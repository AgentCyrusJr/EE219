{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing #superbowl\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import json\n",
    "import time\n",
    "import datetime\n",
    "try:\n",
    "    from sets import Set\n",
    "except ImportError:\n",
    "    Set = set\n",
    "\n",
    "print ('Processing #superbowl')\n",
    "\n",
    "f = io.open('tweet_data/tweets_#superbowl.txt', 'r', encoding='utf8')\n",
    "fea = open('3_3/newfeature_#superbowl', 'w')\n",
    "nex = open('3_3/next_#superbowl', 'w')\n",
    "\n",
    "# 1000 is the estimated max number of hour slots\n",
    "num_tweet = [0] * 1000\n",
    "num_hour = -1\n",
    "\n",
    "hour_follow = 0\n",
    "hour_retweet = 0\n",
    "hour_max_follow = -1\n",
    "hour_ranking_score=0;\n",
    "hour_mention = 0;\n",
    "hour_author = Set([])\n",
    "last_num_hour = 0\n",
    "last_num_tweet = 0\n",
    "\n",
    "# Make sure to go back to file head\n",
    "f_start = f.tell()\n",
    "first_line = f.readline()\n",
    "f.seek(f_start)\n",
    "start_date = (json.loads(first_line))['firstpost_date']\n",
    "# From the nearest o'clock\n",
    "tmp_date = datetime.datetime.fromtimestamp(start_date)\n",
    "tmp_date = tmp_date.replace(minute=0, second=0)\n",
    "start_date = int(time.mktime(tmp_date.timetuple()))\n",
    "\n",
    "for line in f.readlines():\n",
    "\ttweet = json.loads(line)\n",
    "\n",
    "\tpost_date = tweet['firstpost_date']\n",
    "\tnum_hour = int((post_date - start_date) / 3600)\n",
    "\tif num_hour > 999:\n",
    "\t\tprint ('Over boundary of hour slots!')\n",
    "\t\tnum_hour = -2\n",
    "\t\tbreak\n",
    "\tnum_tweet[num_hour] += 1\n",
    "\t\n",
    "\tfollow = tweet['original_author']['followers']\n",
    "\tretweet = tweet['metrics']['citations']['total']\n",
    "\tranking_score=tweet['metrics']['ranking_score']\n",
    "\t\n",
    "\t# Ensure nonzero num_tweet\n",
    "\tif last_num_hour>=376 and last_num_hour<=952 and num_hour!=last_num_hour:\n",
    "\t\tfea.write(str(last_num_tweet))\n",
    "\t\tfea.write(',')\n",
    "\t\tfea.write(str(hour_retweet))\n",
    "\t\tfea.write(',')\n",
    "\t\tfea.write(str(hour_follow))\n",
    "\t\tfea.write(',')\n",
    "\t\tdt = datetime.datetime.fromtimestamp(post_date)\n",
    "\t\tfea.write(str(dt.hour))\n",
    "\t\tfea.write(',')\n",
    "\t\tfea.write(str(hour_ranking_score))\n",
    "\t\tfea.write(',')\n",
    "\t\tfea.write(str(hour_mention))\n",
    "\t\tfea.write(',')\n",
    "\t\tfea.write(str(len(hour_author)))\n",
    "\t\tfea.write('\\n')\n",
    "\tif last_num_hour>=377 and last_num_hour<=953 and num_hour!=last_num_hour:\n",
    "\t\tnex.write(str(last_num_tweet))\n",
    "\t\tnex.write('\\n')\t\t\t\n",
    "\t\n",
    "\tif num_hour == last_num_hour:\n",
    "\t\thour_follow += follow\n",
    "\t\thour_retweet += retweet\n",
    "\t\thour_ranking_score += ranking_score\n",
    "\t\thour_mention += len(tweet['tweet']['entities']['user_mentions'])\n",
    "\t\thour_author.add(tweet['author']['name'])\n",
    "\t\tif follow > hour_max_follow:\n",
    "\t\t\thour_max_follow = follow\n",
    "\telse:\n",
    "\t\thour_follow = follow\n",
    "\t\thour_retweet = retweet\n",
    "\t\thour_max_follow = follow\n",
    "\t\thour_ranking_score = ranking_score\n",
    "\t\thour_mention = len(tweet['tweet']['entities']['user_mentions'])\n",
    "\t\thour_author=Set([])\n",
    "\t\t\n",
    "\tlast_num_hour = num_hour\n",
    "\tlast_num_tweet = num_tweet[num_hour]\n",
    "\n",
    "\n",
    "\t\n",
    "\n",
    "f.close()\n",
    "fea.close()\n",
    "nex.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "#use data from h700 to h800\n",
    "#since the feature starts at h376, we use feature(324:424)\n",
    "\n",
    "X = np.loadtxt('3_3/newfeature_#superbowl', delimiter=',')\n",
    "# add a column of 1s\n",
    "X = sm.add_constant(X)\n",
    "Y = np.loadtxt('3_3/next_#superbowl')\n",
    "\n",
    "model = sm.OLS(Y[324:424], X[324:424])\n",
    "result = model.fit()\n",
    "\n",
    "f = open('3_3/result_#superbowl.txt', 'w')\n",
    "f.write(str(result.summary()))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing #nfl\n"
     ]
    }
   ],
   "source": [
    "print ('Processing #nfl')\n",
    "\n",
    "f = io.open('tweet_data/tweets_#nfl.txt', 'r',encoding='utf8')\n",
    "fea = open('3_3/newfeature_#nfl', 'w')\n",
    "nex = open('3_3/next_#nfl', 'w')\n",
    "\n",
    "# 1000 is the estimated max number of hour slots\n",
    "num_tweet = [0] * 1000\n",
    "num_hour = -1\n",
    "\n",
    "hour_follow = 0\n",
    "hour_retweet = 0\n",
    "hour_max_follow = -1\n",
    "hour_ranking_score=0;\n",
    "hour_mention = 0;\n",
    "hour_author = Set([])\n",
    "last_num_hour = 0\n",
    "last_num_tweet = 0\n",
    "\n",
    "# Make sure to go back to file head\n",
    "f_start = f.tell()\n",
    "first_line = f.readline()\n",
    "f.seek(f_start)\n",
    "start_date = (json.loads(first_line))['firstpost_date']\n",
    "# From the nearest o'clock\n",
    "# tmp_date = datetime.datetime.fromtimestamp(start_date)\n",
    "# tmp_date = tmp_date.replace(minute=0, second=0)\n",
    "# start_date = int(time.mktime(tmp_date.timetuple()))\n",
    "\n",
    "for line in f.readlines():\n",
    "\ttweet = json.loads(line)\n",
    "\n",
    "\tpost_date = tweet['firstpost_date']\n",
    "\tnum_hour = int((post_date - start_date) / 3600)\n",
    "\tif num_hour > 999:\n",
    "\t\tprint ('Over boundary of hour slots!')\n",
    "\t\tnum_hour = -2\n",
    "\t\tbreak\n",
    "\tnum_tweet[num_hour] += 1\n",
    "\t\n",
    "\tfollow = tweet['original_author']['followers']\n",
    "\tretweet = tweet['metrics']['citations']['total']\n",
    "\tranking_score=tweet['metrics']['ranking_score']\n",
    "\t\n",
    "\t# Ensure nonzero num_tweet\n",
    "\tif last_num_hour>=340 and last_num_hour<=914 and num_hour!=last_num_hour:\n",
    "\t\tfea.write(str(last_num_tweet))\n",
    "\t\tfea.write(',')\n",
    "\t\tfea.write(str(hour_retweet))\n",
    "\t\tfea.write(',')\n",
    "\t\tfea.write(str(hour_follow))\n",
    "\t\tfea.write(',')\n",
    "\t\tdt = datetime.datetime.fromtimestamp(post_date)\n",
    "\t\tfea.write(str(dt.hour))\n",
    "\t\tfea.write(',')\n",
    "\t\tfea.write(str(hour_ranking_score))\n",
    "\t\tfea.write(',')\n",
    "\t\tfea.write(str(hour_mention))\n",
    "\t\tfea.write(',')\n",
    "\t\tfea.write(str(len(hour_author)))\n",
    "\t\tfea.write('\\n')\n",
    "\tif last_num_hour>=341 and last_num_hour<=915 and num_hour!=last_num_hour:\n",
    "\t\tnex.write(str(last_num_tweet))\n",
    "\t\tnex.write('\\n')\t\t\t\n",
    "\t\n",
    "\tif num_hour == last_num_hour:\n",
    "\t\thour_follow += follow\n",
    "\t\thour_retweet += retweet\n",
    "\t\thour_ranking_score += ranking_score\n",
    "\t\thour_mention += len(tweet['tweet']['entities']['user_mentions'])\n",
    "\t\thour_author.add(tweet['author']['name'])\n",
    "\t\tif follow > hour_max_follow:\n",
    "\t\t\thour_max_follow = follow\n",
    "\telse:\n",
    "\t\thour_follow = follow\n",
    "\t\thour_retweet = retweet\n",
    "\t\thour_max_follow = follow\n",
    "\t\thour_ranking_score = ranking_score\n",
    "\t\thour_mention = len(tweet['tweet']['entities']['user_mentions'])\n",
    "\t\thour_author=Set([])\n",
    "\t\t\n",
    "\tlast_num_hour = num_hour\n",
    "\tlast_num_tweet = num_tweet[num_hour]\n",
    "\n",
    "\n",
    "\n",
    "f.close()\n",
    "fea.close()\n",
    "nex.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.806\n",
      "Model:                            OLS   Adj. R-squared:                  0.792\n",
      "Method:                 Least Squares   F-statistic:                     54.77\n",
      "Date:                Wed, 22 Mar 2017   Prob (F-statistic):           4.34e-30\n",
      "Time:                        11:16:03   Log-Likelihood:                -809.89\n",
      "No. Observations:                 100   AIC:                             1636.\n",
      "Df Residuals:                      92   BIC:                             1657.\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "const        127.1865    162.594      0.782      0.436      -195.740   450.112\n",
      "x1             4.4626      3.949      1.130      0.261        -3.380    12.305\n",
      "x2            -0.4967      0.277     -1.793      0.076        -1.047     0.053\n",
      "x3          3.222e-05   3.45e-05      0.934      0.353     -3.63e-05     0.000\n",
      "x4           -10.9526     12.524     -0.875      0.384       -35.827    13.922\n",
      "x5            -1.2193      0.835     -1.461      0.147        -2.877     0.438\n",
      "x6             9.1090      1.232      7.394      0.000         6.662    11.556\n",
      "x7             0.4904      0.690      0.710      0.479        -0.881     1.862\n",
      "==============================================================================\n",
      "Omnibus:                       29.918   Durbin-Watson:                   1.744\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              334.236\n",
      "Skew:                          -0.320   Prob(JB):                     2.64e-73\n",
      "Kurtosis:                      11.933   Cond. No.                     2.03e+07\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.03e+07. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "[  1.27186468e+02   4.46261539e+00  -4.96691894e-01   3.22232324e-05\n",
      "  -1.09525929e+01  -1.21932236e+00   9.10899265e+00   4.90389057e-01]\n",
      "0.806476246521\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "#use data from h700 to h800\n",
    "#since the feature starts at h340, here we use from 360 to 460\n",
    "\n",
    "X = np.loadtxt('3_3/newfeature_#nfl', delimiter=',')\n",
    "# add a column of 1s\n",
    "X = sm.add_constant(X)\n",
    "Y = np.loadtxt('3_3/next_#nfl')\n",
    "np.savetxt('tt', X, fmt='%d', delimiter=',')\n",
    "\n",
    "model = sm.OLS(Y[360:460], X[360:460])\n",
    "result = model.fit()\n",
    "\n",
    "print(result.summary())\n",
    "print(result.params)\n",
    "print(result.rsquared)\n",
    "\n",
    "f = open('3_3/result_#nfl.txt', 'w')\n",
    "f.write(str(result.summary()))\n",
    "f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing #superbowl\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import json\n",
    "import time\n",
    "import datetime\n",
    "try:\n",
    "    from sets import Set\n",
    "except ImportError:\n",
    "    Set = set\n",
    "#for the first period(hour 697-816), we take 10*12 data\n",
    "#for the second perid(hour 817-828), we take 1*12 data\n",
    "#for the third period(hour 829-948), we take 10*12 data\n",
    "#we use 12 cross fold validation, which works as well as 10 cross fold validation\n",
    "\n",
    "print ('Processing #superbowl')\n",
    "\n",
    "f = io.open('./tweet_data/tweets_#superbowl.txt', 'r', encoding='utf8')\n",
    "fea1 = open('3_4/newfeature1_#superbowl', 'w')\n",
    "nex1 = open('3_4/next1_#superbowl', 'w')\n",
    "fea2 = open('3_4/newfeature2_#superbowl', 'w')\n",
    "nex2 = open('3_4/next2_#superbowl', 'w')\n",
    "fea3 = open('3_4/newfeature3_#superbowl', 'w')\n",
    "nex3 = open('3_4/next3_#superbowl', 'w')\n",
    "\n",
    "# 1000 is the estimated max number of hour slots\n",
    "num_tweet = [0] * 1000\n",
    "num_hour = -1\n",
    "\n",
    "hour_follow = 0\n",
    "hour_retweet = 0\n",
    "hour_max_follow = -1\n",
    "hour_ranking_score=0;\n",
    "hour_mention = 0;\n",
    "hour_author = Set([])\n",
    "last_num_hour = 0\n",
    "last_num_tweet = 0\n",
    "\n",
    "# Make sure to go back to file head\n",
    "f_start = f.tell()\n",
    "first_line = f.readline()\n",
    "f.seek(f_start)\n",
    "start_date = (json.loads(first_line))['firstpost_date']\n",
    "# From the nearest o'clock\n",
    "tmp_date = datetime.datetime.fromtimestamp(start_date)\n",
    "tmp_date = tmp_date.replace(minute=0, second=0)\n",
    "start_date = int(time.mktime(tmp_date.timetuple()))\n",
    "\n",
    "for line in f.readlines():\n",
    "\ttweet = json.loads(line)\n",
    "\n",
    "\tpost_date = tweet['firstpost_date']\n",
    "\tnum_hour = int((post_date - start_date) / 3600)\n",
    "\tif num_hour > 999:\n",
    "\t\tprint ('Over boundary of hour slots!')\n",
    "\t\tnum_hour = -2\n",
    "\t\tbreak\n",
    "\tnum_tweet[num_hour] += 1\n",
    "\t\n",
    "\tfollow = tweet['original_author']['followers']\n",
    "\tretweet = tweet['metrics']['citations']['total']\n",
    "\tranking_score=tweet['metrics']['ranking_score']\n",
    "\t\n",
    "\t# period 1\n",
    "\tif last_num_hour>=696 and last_num_hour<=815 and num_hour!=last_num_hour:\n",
    "\t\tfea1.write(str(last_num_tweet))\n",
    "\t\tfea1.write(',')\n",
    "\t\tfea1.write(str(hour_retweet))\n",
    "\t\tfea1.write(',')\n",
    "\t\tfea1.write(str(hour_follow))\n",
    "\t\tfea1.write(',')\n",
    "\t\tdt = datetime.datetime.fromtimestamp(post_date)\n",
    "\t\tfea1.write(str(dt.hour))\n",
    "\t\tfea1.write(',')\n",
    "\t\tfea1.write(str(hour_ranking_score))\n",
    "\t\tfea1.write(',')\n",
    "\t\tfea1.write(str(hour_mention))\n",
    "\t\tfea1.write(',')\n",
    "\t\tfea1.write(str(len(hour_author)))\n",
    "\t\tfea1.write('\\n')\n",
    "\tif last_num_hour>=697 and last_num_hour<=816 and num_hour!=last_num_hour:\n",
    "\t\tnex1.write(str(last_num_tweet))\n",
    "\t\tnex1.write('\\n')\t\n",
    "\n",
    "\t# period 2\n",
    "\tif last_num_hour>=816 and last_num_hour<=827 and num_hour!=last_num_hour:\n",
    "\t\tfea2.write(str(last_num_tweet))\n",
    "\t\tfea2.write(',')\n",
    "\t\tfea2.write(str(hour_retweet))\n",
    "\t\tfea2.write(',')\n",
    "\t\tfea2.write(str(hour_follow))\n",
    "\t\tfea2.write(',')\n",
    "\t\tdt = datetime.datetime.fromtimestamp(post_date)\n",
    "\t\tfea2.write(str(dt.hour))\n",
    "\t\tfea2.write(',')\n",
    "\t\tfea2.write(str(hour_ranking_score))\n",
    "\t\tfea2.write(',')\n",
    "\t\tfea2.write(str(hour_mention))\n",
    "\t\tfea2.write(',')\n",
    "\t\tfea2.write(str(len(hour_author)))\n",
    "\t\tfea2.write('\\n')\n",
    "\tif last_num_hour>=817 and last_num_hour<=828 and num_hour!=last_num_hour:\n",
    "\t\tnex2.write(str(last_num_tweet))\n",
    "\t\tnex2.write('\\n')\n",
    "\n",
    "\t# period 3\n",
    "\tif last_num_hour>=828 and last_num_hour<=947 and num_hour!=last_num_hour:\n",
    "\t\tfea3.write(str(last_num_tweet))\n",
    "\t\tfea3.write(',')\n",
    "\t\tfea3.write(str(hour_retweet))\n",
    "\t\tfea3.write(',')\n",
    "\t\tfea3.write(str(hour_follow))\n",
    "\t\tfea3.write(',')\n",
    "\t\tdt = datetime.datetime.fromtimestamp(post_date)\n",
    "\t\tfea3.write(str(dt.hour))\n",
    "\t\tfea3.write(',')\n",
    "\t\tfea3.write(str(hour_ranking_score))\n",
    "\t\tfea3.write(',')\n",
    "\t\tfea3.write(str(hour_mention))\n",
    "\t\tfea3.write(',')\n",
    "\t\tfea3.write(str(len(hour_author)))\n",
    "\t\tfea3.write('\\n')\n",
    "\tif last_num_hour>=829 and last_num_hour<=948 and num_hour!=last_num_hour:\n",
    "\t\tnex3.write(str(last_num_tweet))\n",
    "\t\tnex3.write('\\n')\t\t\n",
    "\t\n",
    "\tif num_hour == last_num_hour:\n",
    "\t\thour_follow += follow\n",
    "\t\thour_retweet += retweet\n",
    "\t\thour_ranking_score += ranking_score\n",
    "\t\thour_mention += len(tweet['tweet']['entities']['user_mentions'])\n",
    "\t\thour_author.add(tweet['author']['name'])\n",
    "\t\tif follow > hour_max_follow:\n",
    "\t\t\thour_max_follow = follow\n",
    "\telse:\n",
    "\t\thour_follow = follow\n",
    "\t\thour_retweet = retweet\n",
    "\t\thour_max_follow = follow\n",
    "\t\thour_ranking_score = ranking_score\n",
    "\t\thour_mention = len(tweet['tweet']['entities']['user_mentions'])\n",
    "\t\thour_author=Set([])\n",
    "\t\t\n",
    "\tlast_num_hour = num_hour\n",
    "\tlast_num_tweet = num_tweet[num_hour]\n",
    "\n",
    "\n",
    "f.close()\n",
    "fea1.close()\n",
    "nex1.close()\n",
    "fea2.close()\n",
    "nex2.close()\n",
    "fea3.close()\n",
    "nex3.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320.05799176\n",
      "54052.2985543\n",
      "1673.26124146\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "X  = np.loadtxt('3_4/newfeature1_#superbowl', delimiter=',')\n",
    "X2 = np.loadtxt('3_4/newfeature2_#superbowl', delimiter=',')\n",
    "X3 = np.loadtxt('3_4/newfeature3_#superbowl', delimiter=',')\n",
    "#choose feature\n",
    "mask=np.logical_not(np.ones(len(X.transpose()),dtype=bool))\n",
    "mask[[1,4,5]]=True\n",
    "X=X.transpose()[mask].transpose()\n",
    "X2=X2.transpose()[mask].transpose()\n",
    "X3=X3.transpose()[mask].transpose()\n",
    "X  = sm.add_constant(X)\n",
    "X2 = sm.add_constant(X2)\n",
    "X3 = sm.add_constant(X3)\n",
    "Y  = np.loadtxt('3_4/next1_#superbowl')\n",
    "Y2 = np.loadtxt('3_4/next2_#superbowl')\n",
    "Y3 = np.loadtxt('3_4/next3_#superbowl')\n",
    "\n",
    "error  = np.zeros(12)\n",
    "error2 = np.zeros(12)\n",
    "error3 = np.zeros(12)\n",
    "\n",
    "#seek for best parameters, which will be used in prob 5\n",
    "minErr = 999999;\n",
    "minErr2 = 999999;\n",
    "minErr3 = 999999;\n",
    "\n",
    "for i in range(12):\n",
    "\tmask=np.ones(len(X),dtype=bool)\n",
    "\tmask2=np.ones(len(X2),dtype=bool)\n",
    "\tmask[i*10:(i+1)*10]=False\n",
    "\tmask2[i*1:(i+1)*1]=False\n",
    "\n",
    "\ttrainData =X [mask]\n",
    "\ttrainData2=X2[mask2]\n",
    "\ttrainData3=X3[mask]\n",
    "\ttrainTar =Y [mask]\n",
    "\ttrainTar2=Y2[mask2]\n",
    "\ttrainTar3=Y3[mask]\n",
    "\ttest_mask=np.logical_not(mask)\n",
    "\ttest_mask2=np.logical_not(mask2)\n",
    "\ttestData=X[test_mask]\n",
    "\ttestData2=X2[test_mask2]\n",
    "\ttestData3=X3[test_mask]\n",
    "\ttestTar=Y[test_mask]\n",
    "\ttestTar2=Y2[test_mask2]\n",
    "\ttestTar3=Y3[test_mask]\n",
    "\n",
    "\tmodel = sm.OLS(trainTar, trainData)\n",
    "\tmodel2 = sm.OLS(trainTar2, trainData2)\n",
    "\tmodel3 = sm.OLS(trainTar3, trainData3)\n",
    "\tresult = model.fit()\n",
    "\tresult2 = model2.fit()\n",
    "\tresult3 = model3.fit()\n",
    "\tparams = result.params\n",
    "\tparams2 = result2.params\n",
    "\tparams3 = result3.params\n",
    "\n",
    "\ttestRes=np.dot(testData,params)\n",
    "\ttestRes2=np.dot(testData2,params2)\n",
    "\ttestRes3=np.dot(testData3,params3)\n",
    "\terror[i] = np.mean(np.abs(testTar-testRes))\n",
    "\terror2[i] = np.mean(np.abs(testTar2-testRes2))\n",
    "\terror3[i] = np.mean(np.abs(testTar3-testRes3))\n",
    "\n",
    "\tif error[i]<minErr:\n",
    "\t\tminErr=error[i]\n",
    "\t\tbestparams=params\n",
    "\tif error2[i]<minErr2:\n",
    "\t\tminErr2=error2[i]\n",
    "\t\tbestparams2=params2\n",
    "\tif error3[i]<minErr3:\n",
    "\t\tminErr3=error3[i]\n",
    "\t\tbestparams3=params3\n",
    "\n",
    "totalError=np.mean(error)\n",
    "totalError2=np.mean(error2)\n",
    "totalError3=np.mean(error3)\n",
    "\n",
    "print (totalError)\n",
    "print (totalError2)\n",
    "print (totalError3)\n",
    "\n",
    "f=open('./3_4/result_#superbowl.txt','w')\n",
    "f.write(str(totalError)+'\\n')\n",
    "f.write(str(totalError2)+'\\n')\n",
    "f.write(str(totalError3)+'\\n')\n",
    "f.write(str(bestparams)+'\\n')\n",
    "f.write(str(bestparams2)+'\\n')\n",
    "f.write(str(bestparams3)+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing #nfl\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import json\n",
    "import time\n",
    "import datetime\n",
    "try:\n",
    "    from sets import Set\n",
    "except ImportError:\n",
    "    Set = set\n",
    "#for the first period(hour 660-779), we take 10*12 data\n",
    "#for the second perid(hour 780-791), we take 1*12 data\n",
    "#for the third period(hour 792-911), we take 10*12 data\n",
    "#we use 12 cross fold validation, which works as well as 10 cross fold validation\n",
    "\n",
    "print ('Processing #nfl')\n",
    "\n",
    "f = io.open('./tweet_data/tweets_#nfl.txt', 'r',encoding='utf8')\n",
    "fea1 = open('3_4/newfeature1_#nfl', 'w')\n",
    "nex1 = open('3_4/next1_#nfl', 'w')\n",
    "fea2 = open('3_4/newfeature2_#nfl', 'w')\n",
    "nex2 = open('3_4/next2_#nfl', 'w')\n",
    "fea3 = open('3_4/newfeature3_#nfl', 'w')\n",
    "nex3 = open('3_4/next3_#nfl', 'w')\n",
    "\n",
    "# 1000 is the estimated max number of hour slots\n",
    "num_tweet = [0] * 1000\n",
    "num_hour = -1\n",
    "\n",
    "hour_follow = 0\n",
    "hour_retweet = 0\n",
    "hour_max_follow = -1\n",
    "hour_ranking_score=0;\n",
    "hour_mention = 0;\n",
    "hour_author = Set([])\n",
    "last_num_hour = 0\n",
    "last_num_tweet = 0\n",
    "\n",
    "# Make sure to go back to file head\n",
    "f_start = f.tell()\n",
    "first_line = f.readline()\n",
    "f.seek(f_start)\n",
    "start_date = (json.loads(first_line))['firstpost_date']\n",
    "# From the nearest o'clock\n",
    "# tmp_date = datetime.datetime.fromtimestamp(start_date)\n",
    "# tmp_date = tmp_date.replace(minute=0, second=0)\n",
    "# start_date = int(time.mktime(tmp_date.timetuple()))\n",
    "\n",
    "for line in f.readlines():\n",
    "\ttweet = json.loads(line)\n",
    "\n",
    "\tpost_date = tweet['firstpost_date']\n",
    "\tnum_hour = int((post_date - start_date) / 3600)\n",
    "\tif num_hour > 999:\n",
    "\t\tprint ('Over boundary of hour slots!')\n",
    "\t\tnum_hour = -2\n",
    "\t\tbreak\n",
    "\tnum_tweet[num_hour] += 1\n",
    "\t\n",
    "\tfollow = tweet['original_author']['followers']\n",
    "\tretweet = tweet['metrics']['citations']['total']\n",
    "\tranking_score=tweet['metrics']['ranking_score']\n",
    "\t\n",
    "\t# period 1\n",
    "\tif last_num_hour>=659 and last_num_hour<=778 and num_hour!=last_num_hour:\n",
    "\t\tfea1.write(str(last_num_tweet))\n",
    "\t\tfea1.write(',')\n",
    "\t\tfea1.write(str(hour_retweet))\n",
    "\t\tfea1.write(',')\n",
    "\t\tfea1.write(str(hour_follow))\n",
    "\t\tfea1.write(',')\n",
    "\t\tdt = datetime.datetime.fromtimestamp(post_date)\n",
    "\t\tfea1.write(str(dt.hour))\n",
    "\t\tfea1.write(',')\n",
    "\t\tfea1.write(str(hour_ranking_score))\n",
    "\t\tfea1.write(',')\n",
    "\t\tfea1.write(str(hour_mention))\n",
    "\t\tfea1.write(',')\n",
    "\t\tfea1.write(str(len(hour_author)))\n",
    "\t\tfea1.write('\\n')\n",
    "\tif last_num_hour>=660 and last_num_hour<=779 and num_hour!=last_num_hour:\n",
    "\t\tnex1.write(str(last_num_tweet))\n",
    "\t\tnex1.write('\\n')\n",
    "\n",
    "\t# period 2\n",
    "\tif last_num_hour>=779 and last_num_hour<=790 and num_hour!=last_num_hour:\n",
    "\t\tfea2.write(str(last_num_tweet))\n",
    "\t\tfea2.write(',')\n",
    "\t\tfea2.write(str(hour_retweet))\n",
    "\t\tfea2.write(',')\n",
    "\t\tfea2.write(str(hour_follow))\n",
    "\t\tfea2.write(',')\n",
    "\t\tdt = datetime.datetime.fromtimestamp(post_date)\n",
    "\t\tfea2.write(str(dt.hour))\n",
    "\t\tfea2.write(',')\n",
    "\t\tfea2.write(str(hour_ranking_score))\n",
    "\t\tfea2.write(',')\n",
    "\t\tfea2.write(str(hour_mention))\n",
    "\t\tfea2.write(',')\n",
    "\t\tfea2.write(str(len(hour_author)))\n",
    "\t\tfea2.write('\\n')\n",
    "\tif last_num_hour>=780 and last_num_hour<=791 and num_hour!=last_num_hour:\n",
    "\t\tnex2.write(str(last_num_tweet))\n",
    "\t\tnex2.write('\\n')\n",
    "\n",
    "\t# period 3\n",
    "\tif last_num_hour>=791 and last_num_hour<=910 and num_hour!=last_num_hour:\n",
    "\t\tfea3.write(str(last_num_tweet))\n",
    "\t\tfea3.write(',')\n",
    "\t\tfea3.write(str(hour_retweet))\n",
    "\t\tfea3.write(',')\n",
    "\t\tfea3.write(str(hour_follow))\n",
    "\t\tfea3.write(',')\n",
    "\t\tdt = datetime.datetime.fromtimestamp(post_date)\n",
    "\t\tfea3.write(str(dt.hour))\n",
    "\t\tfea3.write(',')\n",
    "\t\tfea3.write(str(hour_ranking_score))\n",
    "\t\tfea3.write(',')\n",
    "\t\tfea3.write(str(hour_mention))\n",
    "\t\tfea3.write(',')\n",
    "\t\tfea3.write(str(len(hour_author)))\n",
    "\t\tfea3.write('\\n')\n",
    "\tif last_num_hour>=792 and last_num_hour<=911 and num_hour!=last_num_hour:\n",
    "\t\tnex3.write(str(last_num_tweet))\n",
    "\t\tnex3.write('\\n')\n",
    "\n",
    "\t\n",
    "\tif num_hour == last_num_hour:\n",
    "\t\thour_follow += follow\n",
    "\t\thour_retweet += retweet\n",
    "\t\thour_ranking_score += ranking_score\n",
    "\t\thour_mention += len(tweet['tweet']['entities']['user_mentions'])\n",
    "\t\thour_author.add(tweet['author']['name'])\n",
    "\t\tif follow > hour_max_follow:\n",
    "\t\t\thour_max_follow = follow\n",
    "\telse:\n",
    "\t\thour_follow = follow\n",
    "\t\thour_retweet = retweet\n",
    "\t\thour_max_follow = follow\n",
    "\t\thour_ranking_score = ranking_score\n",
    "\t\thour_mention = len(tweet['tweet']['entities']['user_mentions'])\n",
    "\t\thour_author=Set([])\n",
    "\t\t\n",
    "\tlast_num_hour = num_hour\n",
    "\tlast_num_tweet = num_tweet[num_hour]\n",
    "\n",
    "\n",
    "\n",
    "f.close()\n",
    "fea1.close()\n",
    "nex1.close()\n",
    "fea2.close()\n",
    "nex2.close()\n",
    "fea3.close()\n",
    "nex3.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166.503186861\n",
      "2029.95971515\n",
      "199.29461983\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "X  = np.loadtxt('3_4/newfeature1_#nfl', delimiter=',')\n",
    "X2 = np.loadtxt('3_4/newfeature2_#nfl', delimiter=',')\n",
    "X3 = np.loadtxt('3_4/newfeature3_#nfl', delimiter=',')\n",
    "#choose feature\n",
    "mask=np.logical_not(np.ones(len(X.transpose()),dtype=bool))\n",
    "mask[[1,4,5]]=True\n",
    "X=X.transpose()[mask].transpose()\n",
    "X2=X2.transpose()[mask].transpose()\n",
    "X3=X3.transpose()[mask].transpose()\n",
    "X  = sm.add_constant(X)\n",
    "X2 = sm.add_constant(X2)\n",
    "X3 = sm.add_constant(X3)\n",
    "Y  = np.loadtxt('3_4/next1_#nfl')\n",
    "Y2 = np.loadtxt('3_4/next2_#nfl')\n",
    "Y3 = np.loadtxt('3_4/next3_#nfl')\n",
    "\n",
    "error  = np.zeros(12)\n",
    "error2 = np.zeros(12)\n",
    "error3 = np.zeros(12)\n",
    "\n",
    "#seek for best parameters, which will be used in prob 5\n",
    "minErr = 999999;\n",
    "minErr2 = 999999;\n",
    "minErr3 = 999999;\n",
    "\n",
    "for i in range(12):\n",
    "\tmask=np.ones(len(X),dtype=bool)\n",
    "\tmask2=np.ones(len(X2),dtype=bool)\n",
    "\tmask[i*10:(i+1)*10]=False\n",
    "\tmask2[i*1:(i+1)*1]=False\n",
    "\n",
    "\ttrainData =X [mask]\n",
    "\ttrainData2=X2[mask2]\n",
    "\ttrainData3=X3[mask]\n",
    "\ttrainTar =Y [mask]\n",
    "\ttrainTar2=Y2[mask2]\n",
    "\ttrainTar3=Y3[mask]\n",
    "\ttest_mask=np.logical_not(mask)\n",
    "\ttest_mask2=np.logical_not(mask2)\n",
    "\ttestData=X[test_mask]\n",
    "\ttestData2=X2[test_mask2]\n",
    "\ttestData3=X3[test_mask]\n",
    "\ttestTar=Y[test_mask]\n",
    "\ttestTar2=Y2[test_mask2]\n",
    "\ttestTar3=Y3[test_mask]\n",
    "\n",
    "\tmodel = sm.OLS(trainTar, trainData)\n",
    "\tmodel2 = sm.OLS(trainTar2, trainData2)\n",
    "\tmodel3 = sm.OLS(trainTar3, trainData3)\n",
    "\tresult = model.fit()\n",
    "\tresult2 = model2.fit()\n",
    "\tresult3 = model3.fit()\n",
    "\tparams = result.params\n",
    "\tparams2 = result2.params\n",
    "\tparams3 = result3.params\n",
    "\n",
    "\ttestRes=np.dot(testData,params)\n",
    "\ttestRes2=np.dot(testData2,params2)\n",
    "\ttestRes3=np.dot(testData3,params3)\n",
    "\terror[i] = np.mean(np.abs(testTar-testRes))\n",
    "\terror2[i] = np.mean(np.abs(testTar2-testRes2))\n",
    "\terror3[i] = np.mean(np.abs(testTar3-testRes3))\n",
    "\n",
    "\tif error[i]<minErr:\n",
    "\t\tminErr=error[i]\n",
    "\t\tbestparams=params\n",
    "\tif error2[i]<minErr2:\n",
    "\t\tminErr2=error2[i]\n",
    "\t\tbestparams2=params2\n",
    "\tif error3[i]<minErr3:\n",
    "\t\tminErr3=error3[i]\n",
    "\t\tbestparams3=params3\n",
    "\n",
    "totalError=np.mean(error)\n",
    "totalError2=np.mean(error2)\n",
    "totalError3=np.mean(error3)\n",
    "\n",
    "print (totalError)\n",
    "print (totalError2)\n",
    "print (totalError3)\n",
    "\n",
    "f=open('./3_4/result_#nfl.txt','w')\n",
    "f.write(str(totalError)+'\\n')\n",
    "f.write(str(totalError2)+'\\n')\n",
    "f.write(str(totalError3)+'\\n')\n",
    "f.write(str(bestparams)+'\\n')\n",
    "f.write(str(bestparams2)+'\\n')\n",
    "f.write(str(bestparams3)+'\\n')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing #sample1_period1\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import json\n",
    "import time\n",
    "import datetime\n",
    "try:\n",
    "    from sets import Set\n",
    "except ImportError:\n",
    "    Set = set\n",
    "\n",
    "print ('Processing #sample1_period1')\n",
    "\n",
    "f = io.open('./test_data/sample1_period1.txt', 'r',encoding='utf8')\n",
    "fea = open('./3_5/feature_1', 'w')\n",
    "nex = open('./3_5/next_1', 'w')\n",
    "\n",
    "# 1000 is the estimated max number of hour slots\n",
    "num_tweet = [0] * 1000\n",
    "num_hour = -1\n",
    "\n",
    "hour_follow = 0\n",
    "hour_retweet = 0\n",
    "hour_max_follow = -1\n",
    "hour_ranking_score=0;\n",
    "hour_mention = 0;\n",
    "hour_author = Set([])\n",
    "last_num_hour = 0\n",
    "last_num_tweet = 0\n",
    "\n",
    "# Make sure to go back to file head\n",
    "f_start = f.tell()\n",
    "first_line = f.readline()\n",
    "f.seek(f_start)\n",
    "start_date = (json.loads(first_line))['firstpost_date']\n",
    "# From the nearest o'clock\n",
    "# tmp_date = datetime.datetime.fromtimestamp(start_date)\n",
    "# tmp_date = tmp_date.replace(minute=0, second=0)\n",
    "# start_date = int(time.mktime(tmp_date.timetuple()))\n",
    "\n",
    "for line in f.readlines():\n",
    "\ttweet = json.loads(line)\n",
    "\n",
    "\tpost_date = tweet['firstpost_date']\n",
    "\tnum_hour = int((post_date - start_date) / 3600)\n",
    "\tif num_hour > 999:\n",
    "\t\tprint ('Over boundary of hour slots!')\n",
    "\t\tnum_hour = -2\n",
    "\t\tbreak\n",
    "\tnum_tweet[num_hour] += 1\n",
    "\t\n",
    "\tfollow = tweet['original_author']['followers']\n",
    "\tretweet = tweet['metrics']['citations']['total']\n",
    "\tranking_score=tweet['metrics']['ranking_score']\n",
    "\t\n",
    "\t# Ensure nonzero num_tweet\n",
    "\tif num_hour!=last_num_hour:\n",
    "\t\tfea.write(str(hour_retweet))\n",
    "\t\tfea.write(',')\n",
    "\t\tfea.write(str(hour_ranking_score))\n",
    "\t\tfea.write(',')\n",
    "\t\tfea.write(str(hour_mention))\n",
    "\t\tfea.write('\\n')\n",
    "\t\tnex.write(str(last_num_tweet))\n",
    "\t\tnex.write('\\n')\t\t\t\n",
    "\t\n",
    "\tif num_hour == last_num_hour:\n",
    "\t\thour_follow += follow\n",
    "\t\thour_retweet += retweet\n",
    "\t\thour_ranking_score += ranking_score\n",
    "\t\thour_mention += len(tweet['tweet']['entities']['user_mentions'])\n",
    "\t\thour_author.add(tweet['author']['name'])\n",
    "\t\tif follow > hour_max_follow:\n",
    "\t\t\thour_max_follow = follow\n",
    "\telse:\n",
    "\t\thour_follow = follow\n",
    "\t\thour_retweet = retweet\n",
    "\t\thour_max_follow = follow\n",
    "\t\thour_ranking_score = ranking_score\n",
    "\t\thour_mention = len(tweet['tweet']['entities']['user_mentions'])\n",
    "\t\thour_author=Set([])\n",
    "\t\t\n",
    "\tlast_num_hour = num_hour\n",
    "\tlast_num_tweet = num_tweet[num_hour]\n",
    "\n",
    "\n",
    "\n",
    "f.close()\n",
    "fea.close()\n",
    "nex.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing #sample2_period2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print ('Processing #sample2_period2')\n",
    "\n",
    "f = io.open('./test_data/sample2_period2.txt', 'r',encoding='utf8')\n",
    "fea = open('./3_5/feature_2', 'w')\n",
    "nex = open('./3_5/next_2', 'w')\n",
    "\n",
    "# 1000 is the estimated max number of hour slots\n",
    "num_tweet = [0] * 1000\n",
    "num_hour = -1\n",
    "\n",
    "hour_follow = 0\n",
    "hour_retweet = 0\n",
    "hour_max_follow = -1\n",
    "hour_ranking_score=0;\n",
    "hour_mention = 0;\n",
    "hour_author = Set([])\n",
    "last_num_hour = 0\n",
    "last_num_tweet = 0\n",
    "\n",
    "# Make sure to go back to file head\n",
    "f_start = f.tell()\n",
    "first_line = f.readline()\n",
    "f.seek(f_start)\n",
    "start_date = (json.loads(first_line))['firstpost_date']\n",
    "# From the nearest o'clock\n",
    "# tmp_date = datetime.datetime.fromtimestamp(start_date)\n",
    "# tmp_date = tmp_date.replace(minute=0, second=0)\n",
    "# start_date = int(time.mktime(tmp_date.timetuple()))\n",
    "\n",
    "for line in f.readlines():\n",
    "\ttweet = json.loads(line)\n",
    "\n",
    "\tpost_date = tweet['firstpost_date']\n",
    "\tnum_hour = int((post_date - start_date) / 3600)\n",
    "\tif num_hour > 999:\n",
    "\t\tprint ('Over boundary of hour slots!')\n",
    "\t\tnum_hour = -2\n",
    "\t\tbreak\n",
    "\tnum_tweet[num_hour] += 1\n",
    "\t\n",
    "\tfollow = tweet['original_author']['followers']\n",
    "\tretweet = tweet['metrics']['citations']['total']\n",
    "\tranking_score=tweet['metrics']['ranking_score']\n",
    "\t\n",
    "\t# Ensure nonzero num_tweet\n",
    "\tif num_hour!=last_num_hour:\n",
    "\t\tfea.write(str(hour_retweet))\n",
    "\t\tfea.write(',')\n",
    "\t\tfea.write(str(hour_ranking_score))\n",
    "\t\tfea.write(',')\n",
    "\t\tfea.write(str(hour_mention))\n",
    "\t\tfea.write('\\n')\n",
    "\t\tnex.write(str(last_num_tweet))\n",
    "\t\tnex.write('\\n')\t\t\t\n",
    "\t\n",
    "\tif num_hour == last_num_hour:\n",
    "\t\thour_follow += follow\n",
    "\t\thour_retweet += retweet\n",
    "\t\thour_ranking_score += ranking_score\n",
    "\t\thour_mention += len(tweet['tweet']['entities']['user_mentions'])\n",
    "\t\thour_author.add(tweet['author']['name'])\n",
    "\t\tif follow > hour_max_follow:\n",
    "\t\t\thour_max_follow = follow\n",
    "\telse:\n",
    "\t\thour_follow = follow\n",
    "\t\thour_retweet = retweet\n",
    "\t\thour_max_follow = follow\n",
    "\t\thour_ranking_score = ranking_score\n",
    "\t\thour_mention = len(tweet['tweet']['entities']['user_mentions'])\n",
    "\t\thour_author=Set([])\n",
    "\t\t\n",
    "\tlast_num_hour = num_hour\n",
    "\tlast_num_tweet = num_tweet[num_hour]\n",
    "\n",
    "\n",
    "\n",
    "f.close()\n",
    "fea.close()\n",
    "nex.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing #sample3_period3\n"
     ]
    }
   ],
   "source": [
    "print ('Processing #sample3_period3')\n",
    "\n",
    "f = io.open('./test_data/sample3_period3.txt', 'r',encoding='utf8')\n",
    "fea = open('./3_5/feature_3', 'w')\n",
    "nex = open('./3_5/next_3', 'w')\n",
    "\n",
    "# 1000 is the estimated max number of hour slots\n",
    "num_tweet = [0] * 1000\n",
    "num_hour = -1\n",
    "\n",
    "hour_follow = 0\n",
    "hour_retweet = 0\n",
    "hour_max_follow = -1\n",
    "hour_ranking_score=0;\n",
    "hour_mention = 0;\n",
    "hour_author = Set([])\n",
    "last_num_hour = 0\n",
    "last_num_tweet = 0\n",
    "\n",
    "# Make sure to go back to file head\n",
    "f_start = f.tell()\n",
    "first_line = f.readline()\n",
    "f.seek(f_start)\n",
    "start_date = (json.loads(first_line))['firstpost_date']\n",
    "# From the nearest o'clock\n",
    "# tmp_date = datetime.datetime.fromtimestamp(start_date)\n",
    "# tmp_date = tmp_date.replace(minute=0, second=0)\n",
    "# start_date = int(time.mktime(tmp_date.timetuple()))\n",
    "\n",
    "for line in f.readlines():\n",
    "\ttweet = json.loads(line)\n",
    "\n",
    "\tpost_date = tweet['firstpost_date']\n",
    "\tnum_hour = int((post_date - start_date) / 3600)\n",
    "\tif num_hour > 999:\n",
    "\t\tprint ('Over boundary of hour slots!')\n",
    "\t\tnum_hour = -2\n",
    "\t\tbreak\n",
    "\tnum_tweet[num_hour] += 1\n",
    "\t\n",
    "\tfollow = tweet['original_author']['followers']\n",
    "\tretweet = tweet['metrics']['citations']['total']\n",
    "\tranking_score=tweet['metrics']['ranking_score']\n",
    "\t\n",
    "\t# Ensure nonzero num_tweet\n",
    "\tif num_hour!=last_num_hour:\n",
    "\t\tfea.write(str(hour_retweet))\n",
    "\t\tfea.write(',')\n",
    "\t\tfea.write(str(hour_ranking_score))\n",
    "\t\tfea.write(',')\n",
    "\t\tfea.write(str(hour_mention))\n",
    "\t\tfea.write('\\n')\n",
    "\t\tnex.write(str(last_num_tweet))\n",
    "\t\tnex.write('\\n')\t\t\t\n",
    "\t\n",
    "\tif num_hour == last_num_hour:\n",
    "\t\thour_follow += follow\n",
    "\t\thour_retweet += retweet\n",
    "\t\thour_ranking_score += ranking_score\n",
    "\t\thour_mention += len(tweet['tweet']['entities']['user_mentions'])\n",
    "\t\thour_author.add(tweet['author']['name'])\n",
    "\t\tif follow > hour_max_follow:\n",
    "\t\t\thour_max_follow = follow\n",
    "\telse:\n",
    "\t\thour_follow = follow\n",
    "\t\thour_retweet = retweet\n",
    "\t\thour_max_follow = follow\n",
    "\t\thour_ranking_score = ranking_score\n",
    "\t\thour_mention = len(tweet['tweet']['entities']['user_mentions'])\n",
    "\t\thour_author=Set([])\n",
    "\t\t\n",
    "\tlast_num_hour = num_hour\n",
    "\tlast_num_tweet = num_tweet[num_hour]\n",
    "\n",
    "\n",
    "\n",
    "f.close()\n",
    "fea.close()\n",
    "nex.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing #sample4_period1\n"
     ]
    }
   ],
   "source": [
    "print ('Processing #sample4_period1')\n",
    "\n",
    "f = io.open('./test_data/sample4_period1.txt', 'r',encoding='utf8')\n",
    "fea = open('./3_5/feature_4', 'w')\n",
    "nex = open('./3_5/next_4', 'w')\n",
    "\n",
    "# 1000 is the estimated max number of hour slots\n",
    "num_tweet = [0] * 1000\n",
    "num_hour = -1\n",
    "\n",
    "hour_follow = 0\n",
    "hour_retweet = 0\n",
    "hour_max_follow = -1\n",
    "hour_ranking_score=0;\n",
    "hour_mention = 0;\n",
    "hour_author = Set([])\n",
    "last_num_hour = 0\n",
    "last_num_tweet = 0\n",
    "\n",
    "# Make sure to go back to file head\n",
    "f_start = f.tell()\n",
    "first_line = f.readline()\n",
    "f.seek(f_start)\n",
    "start_date = (json.loads(first_line))['firstpost_date']\n",
    "# From the nearest o'clock\n",
    "# tmp_date = datetime.datetime.fromtimestamp(start_date)\n",
    "# tmp_date = tmp_date.replace(minute=0, second=0)\n",
    "# start_date = int(time.mktime(tmp_date.timetuple()))\n",
    "\n",
    "for line in f.readlines():\n",
    "\ttweet = json.loads(line)\n",
    "\n",
    "\tpost_date = tweet['firstpost_date']\n",
    "\tnum_hour = int((post_date - start_date) / 3600)\n",
    "\tif num_hour > 999:\n",
    "\t\tprint ('Over boundary of hour slots!')\n",
    "\t\tnum_hour = -2\n",
    "\t\tbreak\n",
    "\tnum_tweet[num_hour] += 1\n",
    "\t\n",
    "\tfollow = tweet['original_author']['followers']\n",
    "\tretweet = tweet['metrics']['citations']['total']\n",
    "\tranking_score=tweet['metrics']['ranking_score']\n",
    "\t\n",
    "\t# Ensure nonzero num_tweet\n",
    "\tif num_hour!=last_num_hour:\n",
    "\t\tfea.write(str(hour_retweet))\n",
    "\t\tfea.write(',')\n",
    "\t\tfea.write(str(hour_ranking_score))\n",
    "\t\tfea.write(',')\n",
    "\t\tfea.write(str(hour_mention))\n",
    "\t\tfea.write('\\n')\n",
    "\t\tnex.write(str(last_num_tweet))\n",
    "\t\tnex.write('\\n')\t\t\t\n",
    "\t\n",
    "\tif num_hour == last_num_hour:\n",
    "\t\thour_follow += follow\n",
    "\t\thour_retweet += retweet\n",
    "\t\thour_ranking_score += ranking_score\n",
    "\t\thour_mention += len(tweet['tweet']['entities']['user_mentions'])\n",
    "\t\thour_author.add(tweet['author']['name'])\n",
    "\t\tif follow > hour_max_follow:\n",
    "\t\t\thour_max_follow = follow\n",
    "\telse:\n",
    "\t\thour_follow = follow\n",
    "\t\thour_retweet = retweet\n",
    "\t\thour_max_follow = follow\n",
    "\t\thour_ranking_score = ranking_score\n",
    "\t\thour_mention = len(tweet['tweet']['entities']['user_mentions'])\n",
    "\t\thour_author=Set([])\n",
    "\t\t\n",
    "\tlast_num_hour = num_hour\n",
    "\tlast_num_tweet = num_tweet[num_hour]\n",
    "\n",
    "\n",
    "\n",
    "f.close()\n",
    "fea.close()\n",
    "nex.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing #sample5_period1\n"
     ]
    }
   ],
   "source": [
    "print ('Processing #sample5_period1')\n",
    "\n",
    "f = io.open('./test_data/sample5_period1.txt', 'r',encoding='utf8')\n",
    "fea = open('./3_5/feature_5', 'w')\n",
    "nex = open('./3_5/next_5', 'w')\n",
    "\n",
    "# 1000 is the estimated max number of hour slots\n",
    "num_tweet = [0] * 1000\n",
    "num_hour = -1\n",
    "\n",
    "hour_follow = 0\n",
    "hour_retweet = 0\n",
    "hour_max_follow = -1\n",
    "hour_ranking_score=0;\n",
    "hour_mention = 0;\n",
    "hour_author = Set([])\n",
    "last_num_hour = 0\n",
    "last_num_tweet = 0\n",
    "\n",
    "# Make sure to go back to file head\n",
    "f_start = f.tell()\n",
    "first_line = f.readline()\n",
    "f.seek(f_start)\n",
    "start_date = (json.loads(first_line))['firstpost_date']\n",
    "# From the nearest o'clock\n",
    "# tmp_date = datetime.datetime.fromtimestamp(start_date)\n",
    "# tmp_date = tmp_date.replace(minute=0, second=0)\n",
    "# start_date = int(time.mktime(tmp_date.timetuple()))\n",
    "\n",
    "for line in f.readlines():\n",
    "\ttweet = json.loads(line)\n",
    "\n",
    "\tpost_date = tweet['firstpost_date']\n",
    "\tnum_hour = int((post_date - start_date) / 3600)\n",
    "\tif num_hour > 999:\n",
    "\t\tprint ('Over boundary of hour slots!')\n",
    "\t\tnum_hour = -2\n",
    "\t\tbreak\n",
    "\tnum_tweet[num_hour] += 1\n",
    "\t\n",
    "\tfollow = tweet['original_author']['followers']\n",
    "\tretweet = tweet['metrics']['citations']['total']\n",
    "\tranking_score=tweet['metrics']['ranking_score']\n",
    "\t\n",
    "\t# Ensure nonzero num_tweet\n",
    "\tif num_hour!=last_num_hour:\n",
    "\t\tfea.write(str(hour_retweet))\n",
    "\t\tfea.write(',')\n",
    "\t\tfea.write(str(hour_ranking_score))\n",
    "\t\tfea.write(',')\n",
    "\t\tfea.write(str(hour_mention))\n",
    "\t\tfea.write('\\n')\n",
    "\t\tnex.write(str(last_num_tweet))\n",
    "\t\tnex.write('\\n')\t\t\t\n",
    "\t\n",
    "\tif num_hour == last_num_hour:\n",
    "\t\thour_follow += follow\n",
    "\t\thour_retweet += retweet\n",
    "\t\thour_ranking_score += ranking_score\n",
    "\t\thour_mention += len(tweet['tweet']['entities']['user_mentions'])\n",
    "\t\thour_author.add(tweet['author']['name'])\n",
    "\t\tif follow > hour_max_follow:\n",
    "\t\t\thour_max_follow = follow\n",
    "\telse:\n",
    "\t\thour_follow = follow\n",
    "\t\thour_retweet = retweet\n",
    "\t\thour_max_follow = follow\n",
    "\t\thour_ranking_score = ranking_score\n",
    "\t\thour_mention = len(tweet['tweet']['entities']['user_mentions'])\n",
    "\t\thour_author=Set([])\n",
    "\t\t\n",
    "\tlast_num_hour = num_hour\n",
    "\tlast_num_tweet = num_tweet[num_hour]\n",
    "\n",
    "\n",
    "\n",
    "f.close()\n",
    "fea.close()\n",
    "nex.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing #sample6_period2\n"
     ]
    }
   ],
   "source": [
    "print ('Processing #sample6_period2')\n",
    "\n",
    "f = io.open('./test_data/sample6_period2.txt', 'r',encoding='utf8')\n",
    "fea = open('./3_5/feature_6', 'w')\n",
    "nex = open('./3_5/next_6', 'w')\n",
    "\n",
    "# 1000 is the estimated max number of hour slots\n",
    "num_tweet = [0] * 1000\n",
    "num_hour = -1\n",
    "\n",
    "hour_follow = 0\n",
    "hour_retweet = 0\n",
    "hour_max_follow = -1\n",
    "hour_ranking_score=0;\n",
    "hour_mention = 0;\n",
    "hour_author = Set([])\n",
    "last_num_hour = 0\n",
    "last_num_tweet = 0\n",
    "\n",
    "# Make sure to go back to file head\n",
    "f_start = f.tell()\n",
    "first_line = f.readline()\n",
    "f.seek(f_start)\n",
    "start_date = (json.loads(first_line))['firstpost_date']\n",
    "# From the nearest o'clock\n",
    "# tmp_date = datetime.datetime.fromtimestamp(start_date)\n",
    "# tmp_date = tmp_date.replace(minute=0, second=0)\n",
    "# start_date = int(time.mktime(tmp_date.timetuple()))\n",
    "\n",
    "for line in f.readlines():\n",
    "\ttweet = json.loads(line)\n",
    "\n",
    "\tpost_date = tweet['firstpost_date']\n",
    "\tnum_hour = int((post_date - start_date) / 3600)\n",
    "\tif num_hour > 999:\n",
    "\t\tprint ('Over boundary of hour slots!')\n",
    "\t\tnum_hour = -2\n",
    "\t\tbreak\n",
    "\tnum_tweet[num_hour] += 1\n",
    "\t\n",
    "\tfollow = tweet['original_author']['followers']\n",
    "\tretweet = tweet['metrics']['citations']['total']\n",
    "\tranking_score=tweet['metrics']['ranking_score']\n",
    "\t\n",
    "\t# Ensure nonzero num_tweet\n",
    "\tif num_hour!=last_num_hour:\n",
    "\t\tfea.write(str(hour_retweet))\n",
    "\t\tfea.write(',')\n",
    "\t\tfea.write(str(hour_ranking_score))\n",
    "\t\tfea.write(',')\n",
    "\t\tfea.write(str(hour_mention))\n",
    "\t\tfea.write('\\n')\n",
    "\t\tnex.write(str(last_num_tweet))\n",
    "\t\tnex.write('\\n')\t\t\t\n",
    "\t\n",
    "\tif num_hour == last_num_hour:\n",
    "\t\thour_follow += follow\n",
    "\t\thour_retweet += retweet\n",
    "\t\thour_ranking_score += ranking_score\n",
    "\t\thour_mention += len(tweet['tweet']['entities']['user_mentions'])\n",
    "\t\thour_author.add(tweet['author']['name'])\n",
    "\t\tif follow > hour_max_follow:\n",
    "\t\t\thour_max_follow = follow\n",
    "\telse:\n",
    "\t\thour_follow = follow\n",
    "\t\thour_retweet = retweet\n",
    "\t\thour_max_follow = follow\n",
    "\t\thour_ranking_score = ranking_score\n",
    "\t\thour_mention = len(tweet['tweet']['entities']['user_mentions'])\n",
    "\t\thour_author=Set([])\n",
    "\t\t\n",
    "\tlast_num_hour = num_hour\n",
    "\tlast_num_tweet = num_tweet[num_hour]\n",
    "\n",
    "\n",
    "\n",
    "f.close()\n",
    "fea.close()\n",
    "nex.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing #sample7_period3\n"
     ]
    }
   ],
   "source": [
    "print ('Processing #sample7_period3')\n",
    "\n",
    "f = io.open('./test_data/sample7_period3.txt', 'r',encoding='utf8')\n",
    "fea = open('./3_5/feature_7', 'w')\n",
    "nex = open('./3_5/next_7', 'w')\n",
    "\n",
    "# 1000 is the estimated max number of hour slots\n",
    "num_tweet = [0] * 1000\n",
    "num_hour = -1\n",
    "\n",
    "hour_follow = 0\n",
    "hour_retweet = 0\n",
    "hour_max_follow = -1\n",
    "hour_ranking_score=0;\n",
    "hour_mention = 0;\n",
    "hour_author = Set([])\n",
    "last_num_hour = 0\n",
    "last_num_tweet = 0\n",
    "\n",
    "# Make sure to go back to file head\n",
    "f_start = f.tell()\n",
    "first_line = f.readline()\n",
    "f.seek(f_start)\n",
    "start_date = (json.loads(first_line))['firstpost_date']\n",
    "# From the nearest o'clock\n",
    "# tmp_date = datetime.datetime.fromtimestamp(start_date)\n",
    "# tmp_date = tmp_date.replace(minute=0, second=0)\n",
    "# start_date = int(time.mktime(tmp_date.timetuple()))\n",
    "\n",
    "for line in f.readlines():\n",
    "\ttweet = json.loads(line)\n",
    "\n",
    "\tpost_date = tweet['firstpost_date']\n",
    "\tnum_hour = int((post_date - start_date) / 3600)\n",
    "\tif num_hour > 999:\n",
    "\t\tprint ('Over boundary of hour slots!')\n",
    "\t\tnum_hour = -2\n",
    "\t\tbreak\n",
    "\tnum_tweet[num_hour] += 1\n",
    "\t\n",
    "\tfollow = tweet['original_author']['followers']\n",
    "\tretweet = tweet['metrics']['citations']['total']\n",
    "\tranking_score=tweet['metrics']['ranking_score']\n",
    "\t\n",
    "\t# Ensure nonzero num_tweet\n",
    "\tif num_hour!=last_num_hour:\n",
    "\t\tfea.write(str(hour_retweet))\n",
    "\t\tfea.write(',')\n",
    "\t\tfea.write(str(hour_ranking_score))\n",
    "\t\tfea.write(',')\n",
    "\t\tfea.write(str(hour_mention))\n",
    "\t\tfea.write('\\n')\n",
    "\t\tnex.write(str(last_num_tweet))\n",
    "\t\tnex.write('\\n')\t\t\t\n",
    "\t\n",
    "\tif num_hour == last_num_hour:\n",
    "\t\thour_follow += follow\n",
    "\t\thour_retweet += retweet\n",
    "\t\thour_ranking_score += ranking_score\n",
    "\t\thour_mention += len(tweet['tweet']['entities']['user_mentions'])\n",
    "\t\thour_author.add(tweet['author']['name'])\n",
    "\t\tif follow > hour_max_follow:\n",
    "\t\t\thour_max_follow = follow\n",
    "\telse:\n",
    "\t\thour_follow = follow\n",
    "\t\thour_retweet = retweet\n",
    "\t\thour_max_follow = follow\n",
    "\t\thour_ranking_score = ranking_score\n",
    "\t\thour_mention = len(tweet['tweet']['entities']['user_mentions'])\n",
    "\t\thour_author=Set([])\n",
    "\t\t\n",
    "\tlast_num_hour = num_hour\n",
    "\tlast_num_tweet = num_tweet[num_hour]\n",
    "\n",
    "\n",
    "\n",
    "f.close()\n",
    "fea.close()\n",
    "nex.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing #sample8_period1\n"
     ]
    }
   ],
   "source": [
    "print ('Processing #sample8_period1')\n",
    "\n",
    "f = io.open('./test_data/sample8_period1.txt', 'r',encoding='utf8')\n",
    "fea = open('./3_5/feature_8', 'w')\n",
    "nex = open('./3_5/next_8', 'w')\n",
    "\n",
    "# 1000 is the estimated max number of hour slots\n",
    "num_tweet = [0] * 1000\n",
    "num_hour = -1\n",
    "\n",
    "hour_follow = 0\n",
    "hour_retweet = 0\n",
    "hour_max_follow = -1\n",
    "hour_ranking_score=0;\n",
    "hour_mention = 0;\n",
    "hour_author = Set([])\n",
    "last_num_hour = 0\n",
    "last_num_tweet = 0\n",
    "\n",
    "# Make sure to go back to file head\n",
    "f_start = f.tell()\n",
    "first_line = f.readline()\n",
    "f.seek(f_start)\n",
    "start_date = (json.loads(first_line))['firstpost_date']\n",
    "# From the nearest o'clock\n",
    "# tmp_date = datetime.datetime.fromtimestamp(start_date)\n",
    "# tmp_date = tmp_date.replace(minute=0, second=0)\n",
    "# start_date = int(time.mktime(tmp_date.timetuple()))\n",
    "\n",
    "for line in f.readlines():\n",
    "\ttweet = json.loads(line)\n",
    "\n",
    "\tpost_date = tweet['firstpost_date']\n",
    "\tnum_hour = int((post_date - start_date) / 3600)\n",
    "\tif num_hour > 999:\n",
    "\t\tprint ('Over boundary of hour slots!')\n",
    "\t\tnum_hour = -2\n",
    "\t\tbreak\n",
    "\tnum_tweet[num_hour] += 1\n",
    "\t\n",
    "\tfollow = tweet['original_author']['followers']\n",
    "\tretweet = tweet['metrics']['citations']['total']\n",
    "\tranking_score=tweet['metrics']['ranking_score']\n",
    "\t\n",
    "\t# Ensure nonzero num_tweet\n",
    "\tif num_hour!=last_num_hour:\n",
    "\t\tfea.write(str(hour_retweet))\n",
    "\t\tfea.write(',')\n",
    "\t\tfea.write(str(hour_ranking_score))\n",
    "\t\tfea.write(',')\n",
    "\t\tfea.write(str(hour_mention))\n",
    "\t\tfea.write('\\n')\n",
    "\t\tnex.write(str(last_num_tweet))\n",
    "\t\tnex.write('\\n')\t\t\t\n",
    "\t\n",
    "\tif num_hour == last_num_hour:\n",
    "\t\thour_follow += follow\n",
    "\t\thour_retweet += retweet\n",
    "\t\thour_ranking_score += ranking_score\n",
    "\t\thour_mention += len(tweet['tweet']['entities']['user_mentions'])\n",
    "\t\thour_author.add(tweet['author']['name'])\n",
    "\t\tif follow > hour_max_follow:\n",
    "\t\t\thour_max_follow = follow\n",
    "\telse:\n",
    "\t\thour_follow = follow\n",
    "\t\thour_retweet = retweet\n",
    "\t\thour_max_follow = follow\n",
    "\t\thour_ranking_score = ranking_score\n",
    "\t\thour_mention = len(tweet['tweet']['entities']['user_mentions'])\n",
    "\t\thour_author=Set([])\n",
    "\t\t\n",
    "\tlast_num_hour = num_hour\n",
    "\tlast_num_tweet = num_tweet[num_hour]\n",
    "\n",
    "\n",
    "\n",
    "f.close()\n",
    "fea.close()\n",
    "nex.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing #sample9_period2\n"
     ]
    }
   ],
   "source": [
    "print ('Processing #sample9_period2')\n",
    "\n",
    "f = io.open('./test_data/sample9_period2.txt', 'r',encoding='utf8')\n",
    "fea = open('./3_5/feature_9', 'w')\n",
    "nex = open('./3_5/next_9', 'w')\n",
    "\n",
    "# 1000 is the estimated max number of hour slots\n",
    "num_tweet = [0] * 1000\n",
    "num_hour = -1\n",
    "\n",
    "hour_follow = 0\n",
    "hour_retweet = 0\n",
    "hour_max_follow = -1\n",
    "hour_ranking_score=0;\n",
    "hour_mention = 0;\n",
    "hour_author = Set([])\n",
    "last_num_hour = 0\n",
    "last_num_tweet = 0\n",
    "\n",
    "# Make sure to go back to file head\n",
    "f_start = f.tell()\n",
    "first_line = f.readline()\n",
    "f.seek(f_start)\n",
    "start_date = (json.loads(first_line))['firstpost_date']\n",
    "# From the nearest o'clock\n",
    "# tmp_date = datetime.datetime.fromtimestamp(start_date)\n",
    "# tmp_date = tmp_date.replace(minute=0, second=0)\n",
    "# start_date = int(time.mktime(tmp_date.timetuple()))\n",
    "\n",
    "for line in f.readlines():\n",
    "\ttweet = json.loads(line)\n",
    "\n",
    "\tpost_date = tweet['firstpost_date']\n",
    "\tnum_hour = int((post_date - start_date) / 3600)\n",
    "\tif num_hour > 999:\n",
    "\t\tprint ('Over boundary of hour slots!')\n",
    "\t\tnum_hour = -2\n",
    "\t\tbreak\n",
    "\tnum_tweet[num_hour] += 1\n",
    "\t\n",
    "\tfollow = tweet['original_author']['followers']\n",
    "\tretweet = tweet['metrics']['citations']['total']\n",
    "\tranking_score=tweet['metrics']['ranking_score']\n",
    "\t\n",
    "\t# Ensure nonzero num_tweet\n",
    "\tif num_hour!=last_num_hour:\n",
    "\t\tfea.write(str(hour_retweet))\n",
    "\t\tfea.write(',')\n",
    "\t\tfea.write(str(hour_ranking_score))\n",
    "\t\tfea.write(',')\n",
    "\t\tfea.write(str(hour_mention))\n",
    "\t\tfea.write('\\n')\n",
    "\t\tnex.write(str(last_num_tweet))\n",
    "\t\tnex.write('\\n')\t\t\t\n",
    "\t\n",
    "\tif num_hour == last_num_hour:\n",
    "\t\thour_follow += follow\n",
    "\t\thour_retweet += retweet\n",
    "\t\thour_ranking_score += ranking_score\n",
    "\t\thour_mention += len(tweet['tweet']['entities']['user_mentions'])\n",
    "\t\thour_author.add(tweet['author']['name'])\n",
    "\t\tif follow > hour_max_follow:\n",
    "\t\t\thour_max_follow = follow\n",
    "\telse:\n",
    "\t\thour_follow = follow\n",
    "\t\thour_retweet = retweet\n",
    "\t\thour_max_follow = follow\n",
    "\t\thour_ranking_score = ranking_score\n",
    "\t\thour_mention = len(tweet['tweet']['entities']['user_mentions'])\n",
    "\t\thour_author=Set([])\n",
    "\t\t\n",
    "\tlast_num_hour = num_hour\n",
    "\tlast_num_tweet = num_tweet[num_hour]\n",
    "\n",
    "\n",
    "\n",
    "f.close()\n",
    "fea.close()\n",
    "nex.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing #sample10_period3\n"
     ]
    }
   ],
   "source": [
    "print ('Processing #sample10_period3')\n",
    "\n",
    "f = io.open('./test_data/sample10_period3.txt', 'r',encoding='utf8')\n",
    "fea = open('./3_5/feature_10', 'w')\n",
    "nex = open('./3_5/next_10', 'w')\n",
    "\n",
    "# 1000 is the estimated max number of hour slots\n",
    "num_tweet = [0] * 1000\n",
    "num_hour = -1\n",
    "\n",
    "hour_follow = 0\n",
    "hour_retweet = 0\n",
    "hour_max_follow = -1\n",
    "hour_ranking_score=0;\n",
    "hour_mention = 0;\n",
    "hour_author = Set([])\n",
    "last_num_hour = 0\n",
    "last_num_tweet = 0\n",
    "\n",
    "# Make sure to go back to file head\n",
    "f_start = f.tell()\n",
    "first_line = f.readline()\n",
    "f.seek(f_start)\n",
    "start_date = (json.loads(first_line))['firstpost_date']\n",
    "# From the nearest o'clock\n",
    "# tmp_date = datetime.datetime.fromtimestamp(start_date)\n",
    "# tmp_date = tmp_date.replace(minute=0, second=0)\n",
    "# start_date = int(time.mktime(tmp_date.timetuple()))\n",
    "\n",
    "for line in f.readlines():\n",
    "\ttweet = json.loads(line)\n",
    "\n",
    "\tpost_date = tweet['firstpost_date']\n",
    "\tnum_hour = int((post_date - start_date) / 3600)\n",
    "\tif num_hour > 999:\n",
    "\t\tprint ('Over boundary of hour slots!')\n",
    "\t\tnum_hour = -2\n",
    "\t\tbreak\n",
    "\tnum_tweet[num_hour] += 1\n",
    "\t\n",
    "\tfollow = tweet['original_author']['followers']\n",
    "\tretweet = tweet['metrics']['citations']['total']\n",
    "\tranking_score=tweet['metrics']['ranking_score']\n",
    "\t\n",
    "\t# Ensure nonzero num_tweet\n",
    "\tif num_hour!=last_num_hour:\n",
    "\t\tfea.write(str(hour_retweet))\n",
    "\t\tfea.write(',')\n",
    "\t\tfea.write(str(hour_ranking_score))\n",
    "\t\tfea.write(',')\n",
    "\t\tfea.write(str(hour_mention))\n",
    "\t\tfea.write('\\n')\n",
    "\t\tnex.write(str(last_num_tweet))\n",
    "\t\tnex.write('\\n')\t\t\t\n",
    "\t\n",
    "\tif num_hour == last_num_hour:\n",
    "\t\thour_follow += follow\n",
    "\t\thour_retweet += retweet\n",
    "\t\thour_ranking_score += ranking_score\n",
    "\t\thour_mention += len(tweet['tweet']['entities']['user_mentions'])\n",
    "\t\thour_author.add(tweet['author']['name'])\n",
    "\t\tif follow > hour_max_follow:\n",
    "\t\t\thour_max_follow = follow\n",
    "\telse:\n",
    "\t\thour_follow = follow\n",
    "\t\thour_retweet = retweet\n",
    "\t\thour_max_follow = follow\n",
    "\t\thour_ranking_score = ranking_score\n",
    "\t\thour_mention = len(tweet['tweet']['entities']['user_mentions'])\n",
    "\t\thour_author=Set([])\n",
    "\t\t\n",
    "\tlast_num_hour = num_hour\n",
    "\tlast_num_tweet = num_tweet[num_hour]\n",
    "\n",
    "\n",
    "\n",
    "f.close()\n",
    "fea.close()\n",
    "nex.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "F1 = np.loadtxt('3_5/feature_1_p1',delimiter=',')\n",
    "F2 = np.loadtxt('3_5/feature_2_p2',delimiter=',')\n",
    "F3 = np.loadtxt('3_5/feature_3_p3',delimiter=',')\n",
    "F4 = np.loadtxt('3_5/feature_4_p1',delimiter=',')\n",
    "F5 = np.loadtxt('3_5/feature_5_p1',delimiter=',')\n",
    "F6 = np.loadtxt('3_5/feature_6_p2',delimiter=',')\n",
    "F7 = np.loadtxt('3_5/feature_7_p3',delimiter=',')\n",
    "F8 = np.loadtxt('3_5/feature_8_p1',delimiter=',')\n",
    "F9 = np.loadtxt('3_5/feature_9_p2',delimiter=',')\n",
    "F10 = np.loadtxt('3_5/feature_10_p3',delimiter=',')\n",
    "\n",
    "F1=sm.add_constant(F1)\n",
    "F2=sm.add_constant(F2)\n",
    "F3=sm.add_constant(F3)\n",
    "F4=sm.add_constant(F4)\n",
    "F5=sm.add_constant(F5)\n",
    "F6=sm.add_constant(F6)\n",
    "F7=sm.add_constant(F7)\n",
    "F8=sm.add_constant(F8)\n",
    "F9=sm.add_constant(F9)\n",
    "F10=sm.add_constant(F10)\n",
    "\n",
    "D1 = np.loadtxt('3_5/next_1_p1',delimiter=',')\n",
    "D2 = np.loadtxt('3_5/next_2_p2',delimiter=',')\n",
    "D3 = np.loadtxt('3_5/next_3_p3',delimiter=',')\n",
    "D4 = np.loadtxt('3_5/next_4_p1',delimiter=',')\n",
    "D5 = np.loadtxt('3_5/next_5_p1',delimiter=',')\n",
    "D6 = np.loadtxt('3_5/next_6_p2',delimiter=',')\n",
    "D7 = np.loadtxt('3_5/next_7_p3',delimiter=',')\n",
    "D8 = np.loadtxt('3_5/next_8_p1',delimiter=',')\n",
    "D9 = np.loadtxt('3_5/next_9_p2',delimiter=',')\n",
    "D10 = np.loadtxt('3_5/next_10_p3',delimiter=',')\n",
    "\n",
    "n1Params=np.array([  1.27958012e+02,   8.53394878e-02,   2.95597415e-02,   1.90040400e+00])\n",
    "n2Params=np.array([ -1.81960916e+03,   1.80790216e-01,  -6.61419007e-01,   1.62404171e+01])\n",
    "n3Params=np.array([  3.05503584e+02,  -1.80871799e-01,   1.86474869e-01,  -6.66677145e-01])\n",
    "s1Params=np.array([ 1.27050291,  0.07351563,  0.32799911, -1.13586267])\n",
    "s2Params=np.array([  7.50273608e+03,   6.76986542e+00,  -3.63363797e-01,  -4.38255481e+01])\n",
    "s3Params=np.array([  2.23587570e+02,  -6.44813828e-03,  -1.22968149e-01,   2.46702921e+00])\n",
    "\n",
    "e1n = np.abs(np.dot(F1,n1Params)-D1)\n",
    "e1s = np.abs(np.dot(F1,s1Params)-D1)\n",
    "e2n = np.abs(np.dot(F2,n2Params)-D2)\n",
    "e2s = np.abs(np.dot(F2,s2Params)-D2)\n",
    "e3n = np.abs(np.dot(F3,n3Params)-D3)\n",
    "e3s = np.abs(np.dot(F3,s3Params)-D3)\n",
    "e4n = np.abs(np.dot(F4,n1Params)-D4)\n",
    "e4s = np.abs(np.dot(F4,s1Params)-D4)\n",
    "e5n = np.abs(np.dot(F5,n1Params)-D5)\n",
    "e5s = np.abs(np.dot(F5,s1Params)-D5)\n",
    "e6n = np.abs(np.dot(F6,n2Params)-D6)\n",
    "e6s = np.abs(np.dot(F6,s2Params)-D6)\n",
    "e7n = np.abs(np.dot(F7,n3Params)-D7)\n",
    "e7s = np.abs(np.dot(F7,s3Params)-D7)\n",
    "e8n = np.abs(np.dot(F8,n1Params)-D8)\n",
    "e8s = np.abs(np.dot(F8,s1Params)-D8)\n",
    "e9n = np.abs(np.dot(F9,n2Params)-D9)\n",
    "e9s = np.abs(np.dot(F9,s2Params)-D9)\n",
    "e10n = np.abs(np.dot(F10,n3Params)-D10)\n",
    "e10s = np.abs(np.dot(F10,s3Params)-D10)\n",
    "\n",
    "f=open('./3_5/result.txt','w')\n",
    "f.write('nfl prediction'+'\\n')\n",
    "f.write(str(e1n)+'\\n')\n",
    "f.write(str(e2n)+'\\n')\n",
    "f.write(str(e3n)+'\\n')\n",
    "f.write(str(e4n)+'\\n')\n",
    "f.write(str(e5n)+'\\n')\n",
    "f.write(str(e6n)+'\\n')\n",
    "f.write(str(e7n)+'\\n')\n",
    "f.write(str(e8n)+'\\n')\n",
    "f.write(str(e9n)+'\\n')\n",
    "f.write(str(e10n)+'\\n')\n",
    "f.write('\\n'+'superbowl prediction'+'\\n')\n",
    "f.write(str(e1s)+'\\n')\n",
    "f.write(str(e2s)+'\\n')\n",
    "f.write(str(e3s)+'\\n')\n",
    "f.write(str(e4s)+'\\n')\n",
    "f.write(str(e5s)+'\\n')\n",
    "f.write(str(e6s)+'\\n')\n",
    "f.write(str(e7s)+'\\n')\n",
    "f.write(str(e8s)+'\\n')\n",
    "f.write(str(e9s)+'\\n')\n",
    "f.write(str(e10s)+'\\n')\n",
    "\n",
    "f.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
